{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "columns = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\", \"level\"]\n",
    "attack_type = {\n",
    "    0: 'normal',\n",
    "    1: 'DOS',\n",
    "    2: 'Probe',\n",
    "    3: 'R2L',\n",
    "    4: 'U2R'\n",
    "}\n",
    "\n",
    "new_label = {\n",
    "    'normal': 0,\n",
    "    'apache2': 1,\n",
    "    'back': 1,\n",
    "    'mailbomb': 1,\n",
    "    'processtable': 1,\n",
    "    'snmpgetattack': 1,\n",
    "    'teardrop': 1,\n",
    "    'smurf': 1,\n",
    "    'land': 1,\n",
    "    'neptune': 1,\n",
    "    'pod': 1,\n",
    "    'udpstorm': 1,\n",
    "    'nmap': 2,\n",
    "    'ipsweep': 2,\n",
    "    'portsweep': 2,\n",
    "    'satan': 2,\n",
    "    'mscan': 2,\n",
    "    'saint': 2,\n",
    "    'ftp_write': 3,\n",
    "    'guess_passwd': 3,\n",
    "    'snmpguess': 3,\n",
    "    'imap': 3,\n",
    "    'spy': 3,\n",
    "    'warezclient': 3,\n",
    "    'warezmaster': 3,\n",
    "    'multihop': 3,\n",
    "    'phf': 3,\n",
    "    'imap': 3,\n",
    "    'named': 3,\n",
    "    'sendmail': 3,\n",
    "    'xlock': 3,\n",
    "    'xsnoop': 3,\n",
    "    'worm': 3,\n",
    "    'ps': 4,\n",
    "    'buffer_overflow': 4,\n",
    "    'perl': 4,\n",
    "    'rootkit': 4,\n",
    "    'loadmodule': 4,\n",
    "    'xterm': 4,\n",
    "    'sqlattack': 4,\n",
    "    'httptunnel': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop na and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"NSL-KDD/KDDTrain+.txt\", header=None)\n",
    "train.columns = columns\n",
    "train = train.dropna()\n",
    "train = train.drop_duplicates()\n",
    "test = pd.read_csv(\"NSL-KDD/KDDTest+.txt\", header=None)\n",
    "test.columns = columns\n",
    "test = test.dropna()\n",
    "test = test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_index_train = train.index.to_list()[-1]\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder at `protocol_type`, `service` and `flag` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import encode_text_dummy\n",
    "encode_text_dummy(df=df, name=\"protocol_type\")\n",
    "encode_text_dummy(df=df, name=\"service\")\n",
    "encode_text_dummy(df=df, name=\"flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:last_index_train+1]\n",
    "test = df.iloc[last_index_train+1:]\n",
    "X_train = train.drop(columns=['label', 'level'])\n",
    "y_train = train.label.map(new_label).map(attack_type)\n",
    "X_test = test.drop(columns=['label', 'level'])\n",
    "y_test = test.label.map(new_label).map(attack_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize trainset/testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "features = X_train.columns\n",
    "scalser = MinMaxScaler()\n",
    "scalser.fit(X_train)\n",
    "X_train = scalser.transform(X_train)\n",
    "X_test = scalser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE for balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "desired_samples = {\n",
    "    \"U2R\": 5000,\n",
    "    \"R2L\": 5000\n",
    "}\n",
    "\n",
    "bal = SMOTE(sampling_strategy=desired_samples)\n",
    "\n",
    "X_train, y_train = bal.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP NEURAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=features)\n",
    "X_test = pd.DataFrame(X_test, columns=features)\n",
    "y_train = pd.DataFrame(y_train, columns=['label'])\n",
    "y_test = pd.DataFrame(y_test, columns=['label'])\n",
    "encode_text_dummy(y_train, 'label')\n",
    "encode_text_dummy(y_test, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"NSL-KDD/X_train.csv\")\n",
    "y_train.to_csv(\"NSL-KDD/y_train.csv\")\n",
    "X_test.to_csv(\"NSL-KDD/X_test.csv\")\n",
    "y_test.to_csv(\"NSL-KDD/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from art.estimators.tensorflow import TensorFlowV2Estimator\n",
    "\n",
    "layers = [\n",
    "    tf.keras.layers.Dense(X_train.shape[0], activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "]\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "dnn = tf.keras.models.Sequential(layers=layers)\n",
    "dnn.compile(\n",
    "    loss=loss_object,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "    ]\n",
    ")\n",
    "dnn.fit(\n",
    "    x=X_train,\n",
    "    y=y_train.values,\n",
    "    epochs=5,\n",
    "    batch_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.save(\"NSL-KDD/dnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP and ART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model, train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dnn = tf.keras.models.load_model(\"NSL-KDD/dnn.h5\")\n",
    "X_train = pd.read_csv(\"NSL-KDD/X_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "y_train = pd.read_csv(\"NSL-KDD/y_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "X_test = pd.read_csv(\"NSL-KDD/X_test.csv\").drop(columns=['Unnamed: 0'])\n",
    "y_test = pd.read_csv(\"NSL-KDD/y_test.csv\").drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "dnn_model = TensorFlowV2Classifier(\n",
    "    model=dnn,\n",
    "    loss_object=loss_object,\n",
    "    optimizer=optimizer,\n",
    "    nb_classes=5,\n",
    "    input_shape=X_train.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metric import evaluate_metric\n",
    "evaluate_metric(y_pred=dnn_model.predict(x=X_test), y_true=y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = X_test.sample(n=500)\n",
    "y_samples = y_test.iloc[samples.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metric import evaluate_metric\n",
    "evaluate_metric(\n",
    "    y_pred=dnn_model.predict(x=samples),\n",
    "    y_true=y_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from shap_importance import shap_importance\n",
    "\n",
    "background = pd.read_csv(\"NSL-KDD/samples/background.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "samples = pd.read_csv(\"NSL-KDD/samples/samples.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "y_samples = pd.read_csv(\"NSL-KDD/samples/y_samples.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "explainer = shap.DeepExplainer(model=dnn, data=background.values)\n",
    "shap_vals = explainer.shap_values(samples.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.summary_plot(shap_vals, samples.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy plot when increase number of adversarial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from adversarial_n_best_worst_features import adversarial_n_best_worst_features\n",
    "from shap_importance import shap_importance\n",
    "from art.attacks.evasion.fast_gradient import FastGradientMethod\n",
    "from art.attacks.evasion.iterative_method import BasicIterativeMethod\n",
    "from art.attacks.evasion.saliency_map import SaliencyMapMethod\n",
    "from art.attacks.evasion.carlini import CarliniL0Method, CarliniLInfMethod ,CarliniL2Method\n",
    "from art.attacks.evasion.deepfool import DeepFool\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "\n",
    "dnn = tf.keras.models.load_model(\"NSL-KDD/dnn.h5\")\n",
    "X_train = pd.read_csv(\"NSL-KDD/X_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "y_train = pd.read_csv(\"NSL-KDD/y_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "X_test = pd.read_csv(\"NSL-KDD/X_test.csv\").drop(columns=['Unnamed: 0'])\n",
    "y_test = pd.read_csv(\"NSL-KDD/y_test.csv\").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "dnn_model = TensorFlowV2Classifier(\n",
    "    model=dnn,\n",
    "    loss_object=loss_object,\n",
    "    optimizer=optimizer,\n",
    "    nb_classes=5,\n",
    "    input_shape=X_train.shape\n",
    ")\n",
    "\n",
    "\n",
    "# background = pd.read_csv(\"NSL-KDD/samples/background.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "samples = pd.read_csv(\"NSL-KDD/samples/samples.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "y_samples = pd.read_csv(\"NSL-KDD/samples/y_samples.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "shap_vals = pickle.load(open(\"NSL-KDD/samples/shap_vals_of_samples.pkl\",\"rb\"))\n",
    "shap_vals = [np.array(val) for val in shap_vals]\n",
    "\n",
    "adversarial_algs = {\n",
    "    \"FSGM\": FastGradientMethod(estimator=dnn_model, eps=0.2),\n",
    "    \"BIM\": BasicIterativeMethod(estimator=dnn_model, eps=0.2, max_iter=100, batch_size=32),\n",
    "    \"CW-L2\": CarliniL2Method(classifier=dnn_model, max_iter=10),\n",
    "    \"JSMA\": SaliencyMapMethod(classifier=dnn_model,theta=0.1,gamma=1, batch_size=1),\n",
    "    \"DeepFool\": DeepFool(classifier=dnn_model, max_iter=100, epsilon=0.000001, nb_grads=10, batch_size=1),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features = samples.columns\n",
    "shap_importance_df = shap_importance(full_features, shap_val_of_sample=shap_vals)\n",
    "selected_features = [f for f in shap_importance_df.loc[shap_importance_df['shap_importance']!= 0]['column_name'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate AE sample with popular algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as plk\n",
    "acc_list = []\n",
    "\n",
    "for alg_name in adversarial_algs:\n",
    "    print(f\"{alg_name}\")\n",
    "    alg = adversarial_algs[alg_name]\n",
    "    org_samples = samples.copy()\n",
    "    adv_samples = alg.generate(x=org_samples.values) + np.random.uniform(0,10**-10, size=org_samples.shape)\n",
    "    adv_samples = pd.DataFrame(adv_samples, columns=full_features)\n",
    "    print(f\"\\t{alg_name} finish generate adversarial.\")\n",
    "    pd.DataFrame(np.clip(adv_samples,0,1), columns=full_features).to_csv(f\"NSL-KDD/samples/attack/{alg_name}_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast Gradient Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_on_fsgm = adversarial_n_best_worst_features(\n",
    "    model=dnn_model,\n",
    "    selected_features=selected_features,\n",
    "    samples=samples,\n",
    "    adv_samples=pd.read_csv(\"NSL-KDD/samples/attack/FSGM_sample.csv\"),\n",
    "    y_true=y_samples\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(\n",
    "    [a+1 for a in range(len(selected_features))],\n",
    "    acc_on_fsgm[0], 'red')\n",
    "\n",
    "plt.plot(\n",
    "    [a+1 for a in range(len(selected_features))],\n",
    "    acc_on_fsgm[1] , 'blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Interactive Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc_on_bim = adversarial_n_best_worst_features(\n",
    "    model=dnn_model,\n",
    "    selected_features=selected_features,\n",
    "    samples=samples,\n",
    "    adv_samples=pd.read_csv(\"NSL-KDD/samples/attack/BIM_sample.csv\"),\n",
    "    y_true=y_samples\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    [a+1 for a in range(len(selected_features))],\n",
    "    acc_on_bim[0], 'red')\n",
    "\n",
    "plt.plot(\n",
    "    [a+1 for a in range(len(selected_features))],\n",
    "    acc_on_bim[1] , 'blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carlini L2 Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc_on_cwl2 = adversarial_n_best_worst_features(\n",
    "    model=dnn_model,\n",
    "    selected_features=selected_features,\n",
    "    samples=samples,\n",
    "    adv_samples=pd.read_csv(\"NSL-KDD/samples/attack/CW-L2_sample.csv\"),\n",
    "    y_true=y_samples\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    [a+1 for a in range(len(selected_features))],\n",
    "    acc_on_cwl2[0], 'red')\n",
    "\n",
    "plt.plot(\n",
    "    [a+1 for a in range(len(selected_features))],\n",
    "    acc_on_cwl2[1] , 'blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saliency Map Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc_on_jsma = adversarial_n_best_worst_features(\n",
    "    model=dnn_model,\n",
    "    selected_features=selected_features,\n",
    "    samples=samples,\n",
    "    adv_samples=pd.read_csv(\"NSL-KDD/samples/attack/JSMA_sample.csv\"),\n",
    "    y_true=y_samples\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    [a+1 for a in range(len(selected_features))],\n",
    "    acc_on_jsma[0], 'red')\n",
    "\n",
    "plt.plot(\n",
    "    [a+1 for a in range(len(selected_features))],\n",
    "    acc_on_jsma[1] , 'blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepFool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc_on_deepfool = adversarial_n_best_worst_features(\n",
    "    model=dnn_model,\n",
    "    selected_features=selected_features,\n",
    "    samples=samples,\n",
    "    adv_samples=pd.read_csv(\"NSL-KDD/samples/attack/DeepFool_sample.csv\"),\n",
    "    y_true=y_samples\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    [a+1 for a in range(len(selected_features))],\n",
    "    acc_on_deepfool[0], 'red')\n",
    "\n",
    "plt.plot(\n",
    "    [a+1 for a in range(len(selected_features))],\n",
    "    acc_on_deepfool[1] , 'blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFENSE MECHANISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_dataset(\n",
    "    clean: pd.DataFrame,\n",
    "    fsgm: pd.DataFrame,\n",
    "    bim: pd.DataFrame,\n",
    "    cw_l2: pd.DataFrame,\n",
    "    jsma: pd.DataFrame,\n",
    "    deepfool: pd.DataFrame,\n",
    "    selected_features: list,\n",
    "    shap_importance_feature_values: list,\n",
    "    top_n_features: int = 10\n",
    "):    \n",
    "    n_selected_features = selected_features[:top_n_features]\n",
    "    values = shap_importance_feature_values[:top_n_features]\n",
    "    dfs = [\n",
    "        clean[n_selected_features],\n",
    "        fsgm[n_selected_features],\n",
    "        bim[n_selected_features],\n",
    "        cw_l2[n_selected_features],\n",
    "        jsma[n_selected_features],\n",
    "        deepfool[n_selected_features]\n",
    "        ]\n",
    "    dfs = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    labels = [1 for _ in range(dfs.shape[0])]\n",
    "    labels[:clean.shape[0]] = [0] * clean.shape[0]\n",
    "    labels = pd.DataFrame(\n",
    "        {\"label\":labels}\n",
    "    )\n",
    "    \n",
    "    return pd.concat([dfs, labels], axis=1).sample(frac=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from defense.generate_dataset import generate_dataset\n",
    "\n",
    "samples = pd.read_csv(\"NSL-KDD/samples/samples.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "y_samples = pd.read_csv(\"NSL-KDD/samples/y_samples.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "fsgm_samples = pd.read_csv(\"NSL-KDD/samples/attack/FSGM_sample.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "bim_samples = pd.read_csv(\"NSL-KDD/samples/attack/BIM_sample.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "cwl2_samples = pd.read_csv(\"NSL-KDD/samples/attack/CW-L2_sample.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "jsma_samples = pd.read_csv(\"NSL-KDD/samples/attack/JSMA_sample.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "deepfool_samples = pd.read_csv(\"NSL-KDD/samples/attack/DeepFool_sample.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "shap_importance_df = pd.read_csv(\"NSL-KDD/samples/shap_importance.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "selected_features = shap_importance_df.loc[shap_importance_df['shap_importance'] > 0]['column_name'].values\n",
    "shap_importance_feature_values = shap_importance_df.loc[shap_importance_df['shap_importance'] > 0]['shap_importance'].values\n",
    "\n",
    "defense_data = generate_dataset(\n",
    "    samples,\n",
    "    fsgm_samples,\n",
    "    bim_samples,\n",
    "    cwl2_samples,\n",
    "    jsma_samples,\n",
    "    deepfool_samples,\n",
    "    selected_features,\n",
    "    shap_importance_feature_values,\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_defense_train, x_defense_test, y_defense_train, y_defense_test = train_test_split(\n",
    "    defense_data.drop(columns=['label']),\n",
    "    defense_data['label'],\n",
    "    test_size=0.3,\n",
    "    stratify=defense_data['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1750\n",
       "0     350\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_defense_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "balance_defense = SMOTE(sampling_strategy={0:1000})\n",
    "\n",
    "x_defense_train, y_defense_train = balance_defense.fit_resample(x_defense_train, y_defense_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_auth</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>flag_S0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.285400e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.044097e-11</td>\n",
       "      <td>0.019569</td>\n",
       "      <td>6.199861e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.147215e-12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>5.935846e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.493830e-11</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>9.759503e-11</td>\n",
       "      <td>0.211742</td>\n",
       "      <td>5.394718e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   service_auth  dst_host_srv_count  dst_host_serror_rate  srv_count  \\\n",
       "0  6.285400e-11            1.000000          8.044097e-11   0.019569   \n",
       "1  3.147215e-12            1.000000          1.000000e-02   0.011742   \n",
       "2  4.493830e-11            0.905882          9.759503e-11   0.211742   \n",
       "3  0.000000e+00            0.800000          2.000000e-01   1.000000   \n",
       "4  0.000000e+00            0.890196          0.000000e+00   0.007828   \n",
       "\n",
       "        flag_S0  \n",
       "0  6.199861e-11  \n",
       "1  5.935846e-11  \n",
       "2  5.394718e-11  \n",
       "3  2.000000e-01  \n",
       "4  0.000000e+00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_defense_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def create_cnn(n_features):\n",
    "    ae_detector_dnn = tf.keras.Sequential(\n",
    "        layers=[\n",
    "            tf.keras.layers.Convolution1D(32, 3, padding='same', activation='relu', input_shape=(n_features,1)),\n",
    "            tf.keras.layers.MaxPooling1D(pool_size=(4)),\n",
    "            tf.keras.layers.Convolution1D(64, 3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling1D(pool_size=(2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(2, activation='softmax'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    ae_detector_dnn.compile(\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return ae_detector_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_defense_train = np.reshape(x_defense_train, (x_defense_train.shape[0], x_defense_train.shape[1], 1))\n",
    "x_defense_test = np.reshape(x_defense_test, (x_defense_test.shape[0], x_defense_test.shape[1], 1))\n",
    "y_defense_train = pd.get_dummies(y_defense_train)*1\n",
    "y_defense_test = pd.get_dummies(y_defense_test)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_detector_cnn = create_cnn(x_defense_train.shape[1])\n",
    "ae_detector_cnn.fit(x_defense_train, y_defense_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_detector_cnn.evaluate(x_defense_train, y_defense_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_detector_cnn.evaluate(x_defense_test, y_defense_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
