{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defense.generate_dataset import generate_defense_set, generate_testset\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from evaluation_metric import evaluate_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN DETECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from defense.generate_dataset import generate_dataset\n",
    "\n",
    "samples = pd.read_csv(\"NSL-KDD/X_train.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "y_samples = pd.read_csv(\"NSL-KDD/y_train.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "samples = samples.iloc[np.where(y_samples.label_normal == 0)[0]]\n",
    "y_samples = y_samples.iloc[np.where(y_samples.label_normal == 0)[0]]\n",
    "\n",
    "fsgm_samples = pd.read_csv(\"NSL-KDD/samples/attack/X_FSGM_train.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "bim_samples = pd.read_csv(\"NSL-KDD/samples/attack/X_BIM_train.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "jsma_samples = pd.read_csv(\"NSL-KDD/samples/attack/X_JSMA_train.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "deepfool_samples = pd.read_csv(\"NSL-KDD/samples/attack/X_DeepFool_train.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "full_features = samples.columns\n",
    "shap_importance_df = pd.read_csv(\"NSL-KDD/samples/shap_importance.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "selected_features = shap_importance_df.loc[shap_importance_df['shap_importance'] > 0]['column_name'].values\n",
    "shap_importance_feature_values = shap_importance_df.loc[shap_importance_df['shap_importance'] > 0]['shap_importance'].values\n",
    "selected_features = [i for i in selected_features if 'protocol_type' not in i and 'service' not in i and 'flag' not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dnn = tf.keras.models.load_model(\"NSL-KDD/dnn.h5\")\n",
    "fgsm_pred = dnn.predict(fsgm_samples)\n",
    "bim_pred = dnn.predict(bim_samples)\n",
    "jsma_pred = dnn.predict(jsma_samples)\n",
    "deepfool_pred = dnn.predict(deepfool_samples)\n",
    "fsgm_samples = fsgm_samples.iloc[np.where(np.argmax(fgsm_pred, axis=1)==0)[0]]\n",
    "bim_samples = bim_samples.iloc[np.where(np.argmax(bim_pred, axis=1)==0)[0]]\n",
    "jsma_samples = jsma_samples.iloc[np.where(np.argmax(jsma_pred, axis=1)==0)[0]]\n",
    "deepfool_samples = deepfool_samples.iloc[np.where(np.argmax(deepfool_pred, axis=1)==0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defense Set\n",
      "label\n",
      "0    67583\n",
      "1     9659\n",
      "Name: count, dtype: int64\n",
      "On defense Train\n",
      "label\n",
      "0    47389\n",
      "1    47227\n",
      "Name: count, dtype: int64\n",
      "On defense test\n",
      "label\n",
      "1    20356\n",
      "0    20194\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "defense_data = generate_defense_set(\n",
    "    samples,\n",
    "    fsgm_samples,\n",
    "    bim_samples,\n",
    "    jsma_samples,\n",
    "    deepfool_samples,\n",
    "    selected_features,\n",
    "    shap_importance_feature_values,\n",
    "    36\n",
    ")\n",
    "\n",
    "X_Defenes_Set = defense_data.drop(columns=['label'])\n",
    "y_Defense_Set = defense_data['label']\n",
    "\n",
    "print(\"Defense Set\")\n",
    "print(y_Defense_Set.value_counts())\n",
    "\n",
    "balance_defense = SMOTE(sampling_strategy={1:67583})\n",
    "\n",
    "X_Defenes_Set, y_Defense_Set = balance_defense.fit_resample(X_Defenes_Set, y_Defense_Set)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_defense_train, x_defense_test, y_defense_train, y_defense_test = train_test_split(\n",
    "    X_Defenes_Set,\n",
    "    y_Defense_Set,\n",
    "    test_size=0.3,\n",
    ")\n",
    "\n",
    "print(\"On defense Train\")\n",
    "print(y_defense_train.value_counts())\n",
    "\n",
    "print(\"On defense test\")\n",
    "print(y_defense_test.value_counts())\n",
    "\n",
    "x_defense_train = np.reshape(x_defense_train, (x_defense_train.shape[0], x_defense_train.shape[1], 1))\n",
    "x_defense_test = np.reshape(x_defense_test, (x_defense_test.shape[0], x_defense_test.shape[1], 1))\n",
    "y_defense_train = pd.get_dummies(y_defense_train)*1\n",
    "y_defense_test = pd.get_dummies(y_defense_test)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "93/93 [==============================] - 234s 2s/step - loss: 0.1399 - accuracy: 0.9459\n",
      "Epoch 2/2\n",
      "93/93 [==============================] - 239s 3s/step - loss: 0.0579 - accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd2f3f6b460>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_cnn(n_features):\n",
    "    ae_detector_dnn = tf.keras.Sequential(\n",
    "        layers=[\n",
    "            tf.keras.layers.Convolution1D(2048, 3, padding='same', activation='relu', input_shape=(n_features,1)),\n",
    "            tf.keras.layers.MaxPooling1D(pool_size=4),\n",
    "            tf.keras.layers.Convolution1D(512, 3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.MaxPooling1D(pool_size=4),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(2, activation='softmax'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    ae_detector_dnn.compile(\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return ae_detector_dnn\n",
    "\n",
    "ae_detector_cnn = create_cnn(x_defense_train.shape[1])\n",
    "ae_detector_cnn.fit(x_defense_train, y_defense_train, epochs=2, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RQ1: on test-set from defense data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "def evaluate_metric_bin(y_pred, y_true):\n",
    "\n",
    "    y_pred_ = np.argmax(y_pred, axis=1)\n",
    "    y_true_ = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    return {\n",
    "        \"confusion_matrix\": confusion_matrix(y_true=y_true_, y_pred=y_pred_, labels=[0,1]),\n",
    "        \"accuracy_score\": accuracy_score(y_true=y_true_, y_pred=y_pred_),\n",
    "        \"precision_score\": precision_score(y_true=y_true_, y_pred=y_pred_),\n",
    "        \"recall_score\": recall_score(y_true=y_true_, y_pred=y_pred_),\n",
    "        \"f1_score\": f1_score(y_true=y_true_, y_pred=y_pred_)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2957/2957 [==============================] - 38s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[47265,   124],\n",
       "        [  394, 46833]]),\n",
       " 'accuracy_score': 0.994525238860235,\n",
       " 'precision_score': 0.9973592861554188,\n",
       " 'recall_score': 0.991657314671692,\n",
       " 'f1_score': 0.9945001274101758}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metric_bin(y_pred=ae_detector_cnn.predict(x_defense_train), y_true=y_defense_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1268/1268 [==============================] - 18s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[20146,    48],\n",
       "        [  170, 20186]]),\n",
       " 'accuracy_score': 0.9946239210850801,\n",
       " 'precision_score': 0.997627755263418,\n",
       " 'recall_score': 0.9916486539595205,\n",
       " 'f1_score': 0.9946292190194629}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metric_bin(y_pred=ae_detector_cnn.predict(x_defense_test), y_true=y_defense_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RQ2: on random test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from art.attacks.evasion.fast_gradient import FastGradientMethod\n",
    "# from art.attacks.evasion.iterative_method import BasicIterativeMethod\n",
    "# from art.attacks.evasion.saliency_map import SaliencyMapMethod\n",
    "# from art.attacks.evasion.carlini import CarliniL2Method\n",
    "# from art.attacks.evasion.deepfool import DeepFool\n",
    "\n",
    "# def generate_testset_1(classifier, test_samples: pd.DataFrame, y_test_samples: pd.DataFrame, selected_features: list, n_features: int = 20, random_mode: bool= False):\n",
    "#     import random\n",
    "#     import copy\n",
    "#     full_features = test_samples.columns\n",
    "#     top_n_features = selected_features[:n_features]\n",
    "    \n",
    "#     index_number_n_features = [list(full_features).index(num) for num in top_n_features]\n",
    "    \n",
    "#     adversarial_algs = {\n",
    "#         \"FSGM\": FastGradientMethod(estimator=classifier, eps=0.2),\n",
    "#         \"BIM\": BasicIterativeMethod(estimator=classifier, eps=0.2, max_iter=100, batch_size=32),\n",
    "#         \"JSMA\": SaliencyMapMethod(classifier=classifier,theta=0.1,gamma=1, batch_size=1),\n",
    "#         \"DeepFool\": DeepFool(classifier=classifier, max_iter=100, epsilon=0.000001, nb_grads=10, batch_size=1),\n",
    "#     }\n",
    "#     return_df = test_samples.values\n",
    "#     y_return = []\n",
    "    \n",
    "#     alg_namelist = list(adversarial_algs.keys())\n",
    "    \n",
    "#     np.random.seed(142)\n",
    "    \n",
    "#     for i in range(len(return_df)):\n",
    "#         alg = np.random.choice(alg_namelist, p=[0.25,0.25,0.25,0.25])\n",
    "#         ex = return_df[i]\n",
    "#         ex = ex.reshape(1,ex.shape[0])\n",
    "#         adversarial_algs[alg].generate(x=ex)\n",
    "#         return_df[i, index_number_n_features] = ex[0,index_number_n_features]\n",
    "#         y_return.append(1)\n",
    "\n",
    "    \n",
    "#     return_df = pd.DataFrame(return_df, columns=full_features)\n",
    "    \n",
    "#     return return_df, y_return\n",
    "\n",
    "# dnn = tf.keras.models.load_model(\"NSL-KDD/dnn.h5\")\n",
    "\n",
    "# X_train = pd.read_csv(\"NSL-KDD/X_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "# y_train = pd.read_csv(\"NSL-KDD/y_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "# X_test = pd.read_csv(\"NSL-KDD/X_test.csv\").drop(columns=['Unnamed: 0'])\n",
    "# y_test = pd.read_csv(\"NSL-KDD/y_test.csv\").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "# loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# dnn_model = TensorFlowV2Classifier(\n",
    "#     model=dnn,\n",
    "#     loss_object=loss_object,\n",
    "#     optimizer=optimizer,\n",
    "#     nb_classes=5,\n",
    "#     input_shape=X_train.shape\n",
    "# )\n",
    "\n",
    "# test_samples = X_test.sample(n=5000)\n",
    "# y_test_samples = y_test.iloc[test_samples.index]\n",
    "# test_samples = test_samples.iloc[np.where(y_test_samples.label_normal != 1)[0]]\n",
    "# y_test_samples = y_test_samples.iloc[np.where(y_test_samples.label_normal != 1)[0]]\n",
    "# ae_data, label_ae_data = generate_testset_1(\n",
    "#     dnn_model,\n",
    "#     test_samples,\n",
    "#     y_test_samples,\n",
    "#     selected_features,\n",
    "#     36\n",
    "# )\n",
    "# ae_data.to_csv(\"NSL-KDD/defense/train-test/ae_x_train.csv\")\n",
    "# pd.DataFrame(label_ae_data, columns=['label']).to_csv(\"NSL-KDD/defense/train-test/ae_y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 2s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[2755,  140],\n",
       "        [1316,   32]]),\n",
       " 'accuracy_score': 0.6568465708225312,\n",
       " 'precision_score': 0.18604651162790697,\n",
       " 'recall_score': 0.02373887240356083,\n",
       " 'f1_score': 0.04210526315789474}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Random_Test_Set = pd.read_csv(\"NSL-KDD/defense/random-test-set/X_Random_Test_Set.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "y_Random_Test_Set = pd.read_csv(\"NSL-KDD/defense/random-test-set/y_Random_Test_Set.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "true_label = pd.get_dummies(y_Random_Test_Set, columns=['label'])*1\n",
    "X_Random_Test_Set = X_Random_Test_Set[selected_features[:40]]\n",
    "X_Random_Test_Set = np.reshape(X_Random_Test_Set, (X_Random_Test_Set.shape[0], X_Random_Test_Set.shape[1], 1))\n",
    "evaluate_metric_bin(y_pred=ae_detector_cnn.predict(X_Random_Test_Set), y_true=true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        2895\n",
       "1        1348\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Random_Test_Set.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
